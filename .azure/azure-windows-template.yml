jobs:
  - job: ${{ parameters.name }}
    timeoutInMinutes: 120
    pool:
      vmImage: ${{ parameters.vmImage }}
    strategy:
      maxParallel: 6
    variables:
      STACK_ROOT: $(Build.SourcesDirectory)/sr
      STACK_ARGS: --stack-yaml $(Build.SourcesDirectory)/stack.yaml
  
    steps:
    # Caching steps are inspired from haskell-ide-engine
    # https://github.com/digital-asset/ghcide/blob/master/.azure/windows-stack.yml
    - task: Cache@2
      inputs:
        key: stack-v2 | $(Agent.OS) | $(Build.SourcesDirectory)/stack.yaml | $(Build.SourcesDirectory)/pandoc-plot.cabal
        path: .azure-cache
        cacheHitVar: CACHE_RESTORED
      displayName: "Cache stack-root"
  
    - bash: |
        mkdir -p $STACK_ROOT
        tar -vxzf .azure-cache/stack-root.tar.gz -C /c
        mkdir -p .stack-work
        tar -vxzf .azure-cache/stack-work.tar.gz
      displayName: "Unpack cache"
      condition: eq(variables.CACHE_RESTORED, 'true')
  
    - bash: |
        curl -sSkL http://www.stackage.org/stack/windows-x86_64 -o /usr/bin/stack.zip
        unzip -o /usr/bin/stack.zip -d /usr/bin/
        mkdir -p "$STACK_ROOT"
      displayName: Install stack
  
    - bash: |
        stack setup $STACK_ARGS
      displayName: Install GHC
  
    - bash: |
        stack build $STACK_ARGS --only-dependencies
      displayName: Build dependencies
  
    - bash: |
        stack build $STACK_ARGS
      displayName: Build `pandoc-plot`
  
    - bash: |
        mkdir .azure-deploy
        stack install $STACK_ARGS --local-bin-path .azure-deploy
        cd .azure-deploy
        ARTIFACT_NAME=pandoc-plot-windows-x86_64
        7z a "$(Build.ArtifactStagingDirectory)/$ARTIFACT_NAME.zip" *
      displayName: Install `pandoc-plot`
  
    - bash: |
        stack build $STACK_ARGS --test --bench --only-dependencies
      displayName: Build Test-dependencies
  
      # Note that the task to add conda to PATH must be done
      # in its own step for `source activate ...` command to work.
      # I suspect that the environment variable need to be
      # updated/refreshed, which is done at the beginning of a
      # step
      # https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/anaconda?view=azure-devops&tabs=vs2017#add-conda-to-your-system-path
    - powershell: Write-Host "##vso[task.prependpath]$env:CONDA\Scripts"
      displayName: Add conda to PATH.
    
    - bash: |
        conda create --quiet --yes --name testenv python=3.7
      displayName: Create Python test environment
        
      # Note that Pillow is required to save images to jpg
      # Plotly installation instructions are more complex because we export static images
      # https://plot.ly/python/static-image-export/
    - bash: |
        source activate testenv
        conda install --quiet --yes matplotlib pillow
      displayName: Install Matplotlib toolkit

    - bash: |
        source activate testenv
        conda install --quiet --yes -c conda-forge bokeh selenium geckodriver firefox
      displayName: Install Python/Bokeh toolkit
  
    - bash: |
        source activate testenv
        stack test $STACK_ARGS
      displayName: "Unit tests"

    - bash: |
        stack exec -- pandoc-plot --manual
      displayName: "Testing manual"
    
    - bash: |
        stack install pandoc
        stack install
        source activate testenv
        stack exec -- pandoc --filter pandoc-plot -i tests/integration.md -t html
        echo "Logging output:"
        echo "$(cat log.txt)"
        stack exec -- pandoc-plot clean tests/integration.md
      displayName: "Integration tests"
  
    - publish: $(Build.ArtifactStagingDirectory)/pandoc-plot-windows-x86_64.zip
      artifact: pandoc-plot-windows-x86_64.zip
    
    - bash: |
        mkdir -p .azure-cache
        tar -vczf .azure-cache/stack-root.tar.gz $STACK_ROOT
        tar -vczf .azure-cache/stack-work.tar.gz .stack-work
      displayName: "Pack cache"
  